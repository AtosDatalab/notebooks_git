{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "import pyspark\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jovyan'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('abc').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = pyspark.SparkContext\n",
    "#sc.addFile(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_load = spark.read.csv('hdfs://192.168.122.206:8020/data/vol/depart/*.csv',header='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df=df_load.orderBy('last_update_fme', ascending = False).dropDuplicates(['aircraft_aircrafttype_iatacode','flightstatus_description','timestamps_eobt','airports_next_name','airports_destination_name'])\n",
    "df=df_load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_load_meteo = spark.read.csv('hdfs://192.168.122.206:8020/data/meteo/*.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_load_meteo=df_load_meteo.withColumnRenamed(\"_c0\",\"index\").withColumnRenamed(\"_c1\",\"numero\").withColumnRenamed(\"_c2\",\"pression\").withColumnRenamed(\"_c3\",\"direction_de_vent\").withColumnRenamed(\"_c4\",\"vitesse_de_vent\").withColumnRenamed(\"_c5\",\"temperature\").withColumnRenamed(\"_c6\",\"humidité\").withColumnRenamed(\"_c7\",\"visibilité\").withColumnRenamed(\"_c8\",\"nebulosite\").withColumnRenamed(\"_c9\",\"hauteur_neige\").withColumnRenamed(\"_c10\",\"precipitations_1\").withColumnRenamed(\"_c11\",\"precipitations_3\").withColumnRenamed(\"_c12\",\"nom\").withColumnRenamed(\"_c13\",\"longitude\").withColumnRenamed(\"_c14\",\"latitude\").withColumnRenamed(\"_c15\",\"timestamp\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_load_meteo=df_load_meteo.drop(df_load_meteo.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import from_unixtime,from_utc_timestamp\n",
    "func =  lambda x:from_unixtime(x, format='yyyy-MM-dd HH:mm:ss')\n",
    "df_load_meteo=df_load_meteo.withColumn('timestamp',func(df_load_meteo['timestamp']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_load_meteo=df_load_meteo.dropDuplicates(['nom','timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F\n",
    "df_meteo=df_load_meteo.withColumn(\"timestamp_30_before\", df_load_meteo.timestamp - F.expr('INTERVAL 30 MINUTES') )\n",
    "df_meteo=df_meteo.withColumn(\"timestamp_30_after\", df_load_meteo.timestamp + F.expr('INTERVAL 30 MINUTES') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Lyon_meteo=df_meteo.filter(\"nom = 'Arrondissement de Lyon'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "volX=df_load.toPandas()\n",
    "volX.to_csv(\"volX.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df = df_load.join(df_Lyon_meteo, [df_load.timestamps_eobt < df_Lyon_meteo.timestamp_30_after,df_Lyon_meteo.timestamp_30_before < df_load.timestamps_eobt], how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=joined_df.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_c0</th>\n",
       "      <th>aircraft_aircrafttype_iatacode</th>\n",
       "      <th>aircraft_aircrafttype_icaocode</th>\n",
       "      <th>aircraft_aircrafttype_modelname</th>\n",
       "      <th>airlines_airline_iatacode</th>\n",
       "      <th>airlines_airline_icaocode</th>\n",
       "      <th>airlines_airline_name</th>\n",
       "      <th>airlines_operator_iatacode</th>\n",
       "      <th>airlines_operator_icaocode</th>\n",
       "      <th>airlines_operator_name</th>\n",
       "      <th>...</th>\n",
       "      <th>nebulosite</th>\n",
       "      <th>hauteur_neige</th>\n",
       "      <th>precipitations_1</th>\n",
       "      <th>precipitations_3</th>\n",
       "      <th>nom</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>timestamp_30_before</th>\n",
       "      <th>timestamp_30_after</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>124</td>\n",
       "      <td>320</td>\n",
       "      <td>A320</td>\n",
       "      <td>A320-100/200</td>\n",
       "      <td>LH</td>\n",
       "      <td>DLH</td>\n",
       "      <td>Lufthansa</td>\n",
       "      <td>LH</td>\n",
       "      <td>DLH</td>\n",
       "      <td>Lufthansa</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0.1</td>\n",
       "      <td>0.0.2</td>\n",
       "      <td>Arrondissement de Lyon</td>\n",
       "      <td>45.75</td>\n",
       "      <td>4.58</td>\n",
       "      <td>2020-02-20 13:38:42</td>\n",
       "      <td>2020-02-20 13:08:42</td>\n",
       "      <td>2020-02-20 14:08:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>125</td>\n",
       "      <td>319</td>\n",
       "      <td>A319</td>\n",
       "      <td>A319</td>\n",
       "      <td>EC</td>\n",
       "      <td>EJU</td>\n",
       "      <td>Easy Jet Europe</td>\n",
       "      <td>EC</td>\n",
       "      <td>EJU</td>\n",
       "      <td>Easy Jet Europe</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0.1</td>\n",
       "      <td>0.0.2</td>\n",
       "      <td>Arrondissement de Lyon</td>\n",
       "      <td>45.75</td>\n",
       "      <td>4.58</td>\n",
       "      <td>2020-02-20 13:38:42</td>\n",
       "      <td>2020-02-20 13:08:42</td>\n",
       "      <td>2020-02-20 14:08:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>320</td>\n",
       "      <td>A320</td>\n",
       "      <td>A320-100/200</td>\n",
       "      <td>VY</td>\n",
       "      <td>VLG</td>\n",
       "      <td>Vueling Airlines S.A.</td>\n",
       "      <td>VY</td>\n",
       "      <td>VLG</td>\n",
       "      <td>Vueling Airlines S.A.</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0.1</td>\n",
       "      <td>0.0.2</td>\n",
       "      <td>Arrondissement de Lyon</td>\n",
       "      <td>45.75</td>\n",
       "      <td>4.58</td>\n",
       "      <td>2020-02-20 13:38:42</td>\n",
       "      <td>2020-02-20 13:08:42</td>\n",
       "      <td>2020-02-20 14:08:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>32A</td>\n",
       "      <td>A320</td>\n",
       "      <td>A320-Winglet</td>\n",
       "      <td>LH</td>\n",
       "      <td>DLH</td>\n",
       "      <td>Lufthansa</td>\n",
       "      <td>LH</td>\n",
       "      <td>DLH</td>\n",
       "      <td>Lufthansa</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0.1</td>\n",
       "      <td>0.0.2</td>\n",
       "      <td>Arrondissement de Lyon</td>\n",
       "      <td>45.75</td>\n",
       "      <td>4.58</td>\n",
       "      <td>2020-02-20 13:38:42</td>\n",
       "      <td>2020-02-20 13:08:42</td>\n",
       "      <td>2020-02-20 14:08:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>115</td>\n",
       "      <td>738</td>\n",
       "      <td>B738</td>\n",
       "      <td>737-800 Passenger</td>\n",
       "      <td>AH</td>\n",
       "      <td>DAH</td>\n",
       "      <td>Air Algerie</td>\n",
       "      <td>AH</td>\n",
       "      <td>DAH</td>\n",
       "      <td>Air Algerie</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0.1</td>\n",
       "      <td>0.0.2</td>\n",
       "      <td>Arrondissement de Lyon</td>\n",
       "      <td>45.75</td>\n",
       "      <td>4.58</td>\n",
       "      <td>2020-02-20 13:38:42</td>\n",
       "      <td>2020-02-20 13:08:42</td>\n",
       "      <td>2020-02-20 14:08:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218726</th>\n",
       "      <td>6</td>\n",
       "      <td>320</td>\n",
       "      <td>A320</td>\n",
       "      <td>A320-100/200</td>\n",
       "      <td>EC</td>\n",
       "      <td>EJU</td>\n",
       "      <td>Easy Jet Europe</td>\n",
       "      <td>EC</td>\n",
       "      <td>EJU</td>\n",
       "      <td>Easy Jet Europe</td>\n",
       "      <td>...</td>\n",
       "      <td>57</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0.1</td>\n",
       "      <td>0.0.2</td>\n",
       "      <td>Arrondissement de Lyon</td>\n",
       "      <td>45.75</td>\n",
       "      <td>4.58</td>\n",
       "      <td>2020-02-08 06:57:05</td>\n",
       "      <td>2020-02-08 06:27:05</td>\n",
       "      <td>2020-02-08 07:27:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218727</th>\n",
       "      <td>6</td>\n",
       "      <td>320</td>\n",
       "      <td>A320</td>\n",
       "      <td>A320-100/200</td>\n",
       "      <td>EC</td>\n",
       "      <td>EJU</td>\n",
       "      <td>Easy Jet Europe</td>\n",
       "      <td>EC</td>\n",
       "      <td>EJU</td>\n",
       "      <td>Easy Jet Europe</td>\n",
       "      <td>...</td>\n",
       "      <td>57</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0.1</td>\n",
       "      <td>0.0.2</td>\n",
       "      <td>Arrondissement de Lyon</td>\n",
       "      <td>45.75</td>\n",
       "      <td>4.58</td>\n",
       "      <td>2020-02-08 06:57:05</td>\n",
       "      <td>2020-02-08 06:27:05</td>\n",
       "      <td>2020-02-08 07:27:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218728</th>\n",
       "      <td>6</td>\n",
       "      <td>320</td>\n",
       "      <td>A320</td>\n",
       "      <td>A320-100/200</td>\n",
       "      <td>EC</td>\n",
       "      <td>EJU</td>\n",
       "      <td>Easy Jet Europe</td>\n",
       "      <td>EC</td>\n",
       "      <td>EJU</td>\n",
       "      <td>Easy Jet Europe</td>\n",
       "      <td>...</td>\n",
       "      <td>57</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0.1</td>\n",
       "      <td>0.0.2</td>\n",
       "      <td>Arrondissement de Lyon</td>\n",
       "      <td>45.75</td>\n",
       "      <td>4.58</td>\n",
       "      <td>2020-02-08 06:57:05</td>\n",
       "      <td>2020-02-08 06:27:05</td>\n",
       "      <td>2020-02-08 07:27:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218729</th>\n",
       "      <td>6</td>\n",
       "      <td>320</td>\n",
       "      <td>A320</td>\n",
       "      <td>A320-100/200</td>\n",
       "      <td>EC</td>\n",
       "      <td>EJU</td>\n",
       "      <td>Easy Jet Europe</td>\n",
       "      <td>EC</td>\n",
       "      <td>EJU</td>\n",
       "      <td>Easy Jet Europe</td>\n",
       "      <td>...</td>\n",
       "      <td>57</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0.1</td>\n",
       "      <td>0.0.2</td>\n",
       "      <td>Arrondissement de Lyon</td>\n",
       "      <td>45.75</td>\n",
       "      <td>4.58</td>\n",
       "      <td>2020-02-08 06:57:05</td>\n",
       "      <td>2020-02-08 06:27:05</td>\n",
       "      <td>2020-02-08 07:27:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218730</th>\n",
       "      <td>6</td>\n",
       "      <td>320</td>\n",
       "      <td>A320</td>\n",
       "      <td>A320-100/200</td>\n",
       "      <td>EC</td>\n",
       "      <td>EJU</td>\n",
       "      <td>Easy Jet Europe</td>\n",
       "      <td>EC</td>\n",
       "      <td>EJU</td>\n",
       "      <td>Easy Jet Europe</td>\n",
       "      <td>...</td>\n",
       "      <td>57</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0.1</td>\n",
       "      <td>0.0.2</td>\n",
       "      <td>Arrondissement de Lyon</td>\n",
       "      <td>45.75</td>\n",
       "      <td>4.58</td>\n",
       "      <td>2020-02-08 06:57:05</td>\n",
       "      <td>2020-02-08 06:27:05</td>\n",
       "      <td>2020-02-08 07:27:05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>218731 rows × 67 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        _c0 aircraft_aircrafttype_iatacode aircraft_aircrafttype_icaocode  \\\n",
       "0       124                            320                           A320   \n",
       "1       125                            319                           A319   \n",
       "2         2                            320                           A320   \n",
       "3         3                            32A                           A320   \n",
       "4       115                            738                           B738   \n",
       "...     ...                            ...                            ...   \n",
       "218726    6                            320                           A320   \n",
       "218727    6                            320                           A320   \n",
       "218728    6                            320                           A320   \n",
       "218729    6                            320                           A320   \n",
       "218730    6                            320                           A320   \n",
       "\n",
       "       aircraft_aircrafttype_modelname airlines_airline_iatacode  \\\n",
       "0                         A320-100/200                        LH   \n",
       "1                                 A319                        EC   \n",
       "2                         A320-100/200                        VY   \n",
       "3                         A320-Winglet                        LH   \n",
       "4                    737-800 Passenger                        AH   \n",
       "...                                ...                       ...   \n",
       "218726                    A320-100/200                        EC   \n",
       "218727                    A320-100/200                        EC   \n",
       "218728                    A320-100/200                        EC   \n",
       "218729                    A320-100/200                        EC   \n",
       "218730                    A320-100/200                        EC   \n",
       "\n",
       "       airlines_airline_icaocode  airlines_airline_name  \\\n",
       "0                            DLH              Lufthansa   \n",
       "1                            EJU        Easy Jet Europe   \n",
       "2                            VLG  Vueling Airlines S.A.   \n",
       "3                            DLH              Lufthansa   \n",
       "4                            DAH            Air Algerie   \n",
       "...                          ...                    ...   \n",
       "218726                       EJU        Easy Jet Europe   \n",
       "218727                       EJU        Easy Jet Europe   \n",
       "218728                       EJU        Easy Jet Europe   \n",
       "218729                       EJU        Easy Jet Europe   \n",
       "218730                       EJU        Easy Jet Europe   \n",
       "\n",
       "       airlines_operator_iatacode airlines_operator_icaocode  \\\n",
       "0                              LH                        DLH   \n",
       "1                              EC                        EJU   \n",
       "2                              VY                        VLG   \n",
       "3                              LH                        DLH   \n",
       "4                              AH                        DAH   \n",
       "...                           ...                        ...   \n",
       "218726                         EC                        EJU   \n",
       "218727                         EC                        EJU   \n",
       "218728                         EC                        EJU   \n",
       "218729                         EC                        EJU   \n",
       "218730                         EC                        EJU   \n",
       "\n",
       "       airlines_operator_name  ... nebulosite hauteur_neige precipitations_1  \\\n",
       "0                   Lufthansa  ...          0           0.0            0.0.1   \n",
       "1             Easy Jet Europe  ...          0           0.0            0.0.1   \n",
       "2       Vueling Airlines S.A.  ...          0           0.0            0.0.1   \n",
       "3                   Lufthansa  ...          0           0.0            0.0.1   \n",
       "4                 Air Algerie  ...          0           0.0            0.0.1   \n",
       "...                       ...  ...        ...           ...              ...   \n",
       "218726        Easy Jet Europe  ...         57           0.0            0.0.1   \n",
       "218727        Easy Jet Europe  ...         57           0.0            0.0.1   \n",
       "218728        Easy Jet Europe  ...         57           0.0            0.0.1   \n",
       "218729        Easy Jet Europe  ...         57           0.0            0.0.1   \n",
       "218730        Easy Jet Europe  ...         57           0.0            0.0.1   \n",
       "\n",
       "       precipitations_3                     nom longitude latitude  \\\n",
       "0                 0.0.2  Arrondissement de Lyon     45.75     4.58   \n",
       "1                 0.0.2  Arrondissement de Lyon     45.75     4.58   \n",
       "2                 0.0.2  Arrondissement de Lyon     45.75     4.58   \n",
       "3                 0.0.2  Arrondissement de Lyon     45.75     4.58   \n",
       "4                 0.0.2  Arrondissement de Lyon     45.75     4.58   \n",
       "...                 ...                     ...       ...      ...   \n",
       "218726            0.0.2  Arrondissement de Lyon     45.75     4.58   \n",
       "218727            0.0.2  Arrondissement de Lyon     45.75     4.58   \n",
       "218728            0.0.2  Arrondissement de Lyon     45.75     4.58   \n",
       "218729            0.0.2  Arrondissement de Lyon     45.75     4.58   \n",
       "218730            0.0.2  Arrondissement de Lyon     45.75     4.58   \n",
       "\n",
       "                  timestamp  timestamp_30_before   timestamp_30_after  \n",
       "0       2020-02-20 13:38:42  2020-02-20 13:08:42  2020-02-20 14:08:42  \n",
       "1       2020-02-20 13:38:42  2020-02-20 13:08:42  2020-02-20 14:08:42  \n",
       "2       2020-02-20 13:38:42  2020-02-20 13:08:42  2020-02-20 14:08:42  \n",
       "3       2020-02-20 13:38:42  2020-02-20 13:08:42  2020-02-20 14:08:42  \n",
       "4       2020-02-20 13:38:42  2020-02-20 13:08:42  2020-02-20 14:08:42  \n",
       "...                     ...                  ...                  ...  \n",
       "218726  2020-02-08 06:57:05  2020-02-08 06:27:05  2020-02-08 07:27:05  \n",
       "218727  2020-02-08 06:57:05  2020-02-08 06:27:05  2020-02-08 07:27:05  \n",
       "218728  2020-02-08 06:57:05  2020-02-08 06:27:05  2020-02-08 07:27:05  \n",
       "218729  2020-02-08 06:57:05  2020-02-08 06:27:05  2020-02-08 07:27:05  \n",
       "218730  2020-02-08 06:57:05  2020-02-08 06:27:05  2020-02-08 07:27:05  \n",
       "\n",
       "[218731 rows x 67 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "df.replace(to_replace='None', value=np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o96.showString.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 4 in stage 9.0 failed 1 times, most recent failure: Lost task 4.0 in stage 9.0 (TID 29468, localhost, executor driver): java.io.FileNotFoundException: /tmp/blockmgr-4288a598-97a6-46e0-8cfe-71ef220a0534/2d/temp_shuffle_5ba98bc7-4cc1-47a9-b5dc-c8ec1032c84a (No space left on device)\n\tat java.io.FileOutputStream.open0(Native Method)\n\tat java.io.FileOutputStream.open(FileOutputStream.java:270)\n\tat java.io.FileOutputStream.<init>(FileOutputStream.java:213)\n\tat org.apache.spark.storage.DiskBlockObjectWriter.initialize(DiskBlockObjectWriter.scala:103)\n\tat org.apache.spark.storage.DiskBlockObjectWriter.open(DiskBlockObjectWriter.scala:116)\n\tat org.apache.spark.storage.DiskBlockObjectWriter.write(DiskBlockObjectWriter.scala:237)\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:151)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:123)\n\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1889)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1877)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1876)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1876)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)\n\tat scala.Option.foreach(Option.scala:257)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:926)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2110)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2059)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2048)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:737)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2061)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2082)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2101)\n\tat org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:365)\n\tat org.apache.spark.sql.execution.CollectLimitExec.executeCollect(limit.scala:38)\n\tat org.apache.spark.sql.Dataset.org$apache$spark$sql$Dataset$$collectFromPlan(Dataset.scala:3389)\n\tat org.apache.spark.sql.Dataset$$anonfun$head$1.apply(Dataset.scala:2550)\n\tat org.apache.spark.sql.Dataset$$anonfun$head$1.apply(Dataset.scala:2550)\n\tat org.apache.spark.sql.Dataset$$anonfun$52.apply(Dataset.scala:3370)\n\tat org.apache.spark.sql.execution.SQLExecution$$anonfun$withNewExecutionId$1.apply(SQLExecution.scala:78)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:125)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:73)\n\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3369)\n\tat org.apache.spark.sql.Dataset.head(Dataset.scala:2550)\n\tat org.apache.spark.sql.Dataset.take(Dataset.scala:2764)\n\tat org.apache.spark.sql.Dataset.getRows(Dataset.scala:254)\n\tat org.apache.spark.sql.Dataset.showString(Dataset.scala:291)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: java.io.FileNotFoundException: /tmp/blockmgr-4288a598-97a6-46e0-8cfe-71ef220a0534/2d/temp_shuffle_5ba98bc7-4cc1-47a9-b5dc-c8ec1032c84a (No space left on device)\n\tat java.io.FileOutputStream.open0(Native Method)\n\tat java.io.FileOutputStream.open(FileOutputStream.java:270)\n\tat java.io.FileOutputStream.<init>(FileOutputStream.java:213)\n\tat org.apache.spark.storage.DiskBlockObjectWriter.initialize(DiskBlockObjectWriter.scala:103)\n\tat org.apache.spark.storage.DiskBlockObjectWriter.open(DiskBlockObjectWriter.scala:116)\n\tat org.apache.spark.storage.DiskBlockObjectWriter.write(DiskBlockObjectWriter.scala:237)\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:151)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:123)\n\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\t... 1 more\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-38780cffb0a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mjoined_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepartition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/spark/python/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mshow\u001b[0;34m(self, n, truncate, vertical)\u001b[0m\n\u001b[1;32m    378\u001b[0m         \"\"\"\n\u001b[1;32m    379\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtruncate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtruncate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 380\u001b[0;31m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshowString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvertical\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    381\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshowString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtruncate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvertical\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1255\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1257\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    326\u001b[0m                 raise Py4JJavaError(\n\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 raise Py4JError(\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o96.showString.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 4 in stage 9.0 failed 1 times, most recent failure: Lost task 4.0 in stage 9.0 (TID 29468, localhost, executor driver): java.io.FileNotFoundException: /tmp/blockmgr-4288a598-97a6-46e0-8cfe-71ef220a0534/2d/temp_shuffle_5ba98bc7-4cc1-47a9-b5dc-c8ec1032c84a (No space left on device)\n\tat java.io.FileOutputStream.open0(Native Method)\n\tat java.io.FileOutputStream.open(FileOutputStream.java:270)\n\tat java.io.FileOutputStream.<init>(FileOutputStream.java:213)\n\tat org.apache.spark.storage.DiskBlockObjectWriter.initialize(DiskBlockObjectWriter.scala:103)\n\tat org.apache.spark.storage.DiskBlockObjectWriter.open(DiskBlockObjectWriter.scala:116)\n\tat org.apache.spark.storage.DiskBlockObjectWriter.write(DiskBlockObjectWriter.scala:237)\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:151)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:123)\n\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1889)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1877)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1876)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1876)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)\n\tat scala.Option.foreach(Option.scala:257)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:926)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2110)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2059)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2048)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:737)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2061)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2082)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2101)\n\tat org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:365)\n\tat org.apache.spark.sql.execution.CollectLimitExec.executeCollect(limit.scala:38)\n\tat org.apache.spark.sql.Dataset.org$apache$spark$sql$Dataset$$collectFromPlan(Dataset.scala:3389)\n\tat org.apache.spark.sql.Dataset$$anonfun$head$1.apply(Dataset.scala:2550)\n\tat org.apache.spark.sql.Dataset$$anonfun$head$1.apply(Dataset.scala:2550)\n\tat org.apache.spark.sql.Dataset$$anonfun$52.apply(Dataset.scala:3370)\n\tat org.apache.spark.sql.execution.SQLExecution$$anonfun$withNewExecutionId$1.apply(SQLExecution.scala:78)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:125)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:73)\n\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3369)\n\tat org.apache.spark.sql.Dataset.head(Dataset.scala:2550)\n\tat org.apache.spark.sql.Dataset.take(Dataset.scala:2764)\n\tat org.apache.spark.sql.Dataset.getRows(Dataset.scala:254)\n\tat org.apache.spark.sql.Dataset.showString(Dataset.scala:291)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: java.io.FileNotFoundException: /tmp/blockmgr-4288a598-97a6-46e0-8cfe-71ef220a0534/2d/temp_shuffle_5ba98bc7-4cc1-47a9-b5dc-c8ec1032c84a (No space left on device)\n\tat java.io.FileOutputStream.open0(Native Method)\n\tat java.io.FileOutputStream.open(FileOutputStream.java:270)\n\tat java.io.FileOutputStream.<init>(FileOutputStream.java:213)\n\tat org.apache.spark.storage.DiskBlockObjectWriter.initialize(DiskBlockObjectWriter.scala:103)\n\tat org.apache.spark.storage.DiskBlockObjectWriter.open(DiskBlockObjectWriter.scala:116)\n\tat org.apache.spark.storage.DiskBlockObjectWriter.write(DiskBlockObjectWriter.scala:237)\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:151)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:123)\n\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\t... 1 more\n"
     ]
    }
   ],
   "source": [
    "joined_df.repartition(1).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[ 'flightstatus_code',\n",
    "       'flightstatus_description', 'gid', 'last_update_fme', 'publiccomment',\n",
    "       'remark_code', 'remark_description', 'servicetype_description',]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[ 'flightstatus_code','publiccomment',\n",
    "       'flightstatus_description','aircraft_aircrafttype_iatacode','timestamps_eobt','timestamps_sobt','airports_destination_name','timestamps_modificationdate']].sort_values(by=['aircraft_aircrafttype_iatacode','timestamps_eobt','airports_destination_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(df[df['remark_description']=='Take off/Started'].remark_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(df['flightstatus_description'].values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(subset=['timestamps_aobt']).isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbis=df.dropna(subset=['timestamps_aobt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbis[[ 'aircraft_aircrafttype_iatacode',\n",
    "       'aircraft_aircrafttype_icaocode', 'aircraft_aircrafttype_modelname',\n",
    "       'airlines_airline_name', \n",
    "       'airlines_operator_icaocode', 'airlines_operator_name',\n",
    "       'airports_destination_iatacode', 'airports_destination_icaocode',\n",
    "       'airports_destination_name', 'airports_next_iatacode',\n",
    "       'airports_next_icaocode', 'airports_next_name', 'countrytype_code',\n",
    "       'countrytype_description', 'flightnumbers_callsign',\n",
    "       'flightnumbers_iataflightnumber', 'flightnumbers_icaoflightnumber',\n",
    "       'flightnumbers_internalflightnumber',\n",
    "       'flightnumbers_operatoriataflightnumber',\n",
    "       'flightnumbers_operatoricaoflightnumber',\n",
    "       'flightnumbers_operatorinternalflightnumber', 'flightnumbers_operatortripnumber','flightnumbers_tripnumber', 'flightstatus_code',\n",
    "       'flightstatus_description', 'gid', 'last_update_fme', 'servicetype_description',\n",
    "       'servicetype_iatacode', 'timestamps_aobt', 'timestamps_eobt',\n",
    "       'timestamps_modificationdate', 'timestamps_sobt',\n",
    "       'turnflightinternalid','pression', 'direction_de_vent',\n",
    "       'vitesse_de_vent', 'temperature', 'humidité', 'visibilité',\n",
    "       'nebulosite', 'hauteur_neige']].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbis['pression']=dbis['pression'].astype('int')\n",
    "dbis['direction_de_vent']=dbis['direction_de_vent'].astype('int')\n",
    "dbis['vitesse_de_vent']=dbis['vitesse_de_vent'].astype('float')\n",
    "dbis['temperature']=dbis['temperature'].astype('float')\n",
    "dbis['humidité']=dbis['humidité'].astype('float')\n",
    "dbis['visibilité']=dbis['visibilité'].astype('float')\n",
    "dbis['nebulosite']=dbis['nebulosite'].astype('float')\n",
    "dbis['hauteur_neige']=dbis['hauteur_neige'].astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change(row):\n",
    "    row['day']=row['timestamps_sobt'].day\n",
    "    row['month']=row[\"timestamps_sobt\"].month\n",
    "    row['year']=row[\"timestamps_sobt\"].year\n",
    "    row['hour']=row[\"timestamps_sobt\"].hour\n",
    "    row['minute']=row[\"timestamps_sobt\"].minute\n",
    "    if((row['timestamps_eobt']-row['timestamps_sobt']).seconds/60 < 1000):\n",
    "        row['delay']=int((row['timestamps_eobt']-row['timestamps_sobt']).seconds/60)\n",
    "    elif((row['timestamps_eobt']-row['timestamps_sobt']).seconds/60 >1000):\n",
    "        row['delay']=int((row['timestamps_sobt']-row['timestamps_eobt']).seconds/60)*-1\n",
    "    else :\n",
    "        row['delay']=0\n",
    "    \n",
    "    \n",
    "    return row\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbis=df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbis.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "dbis['timestamps_eobt'] = dbis['timestamps_eobt'].apply(lambda x: datetime.strptime(str(x), \"%Y-%m-%d %H:%M:%S\"))\n",
    "dbis['timestamps_sobt'] =dbis['timestamps_sobt'].apply(lambda x: datetime.strptime(str(x), \"%Y-%m-%d %H:%M:%S\"))\n",
    "dbis=dbis.apply(lambda x:change(x),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbis.to_csv(\"joined.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbis=dbis[[ 'aircraft_aircrafttype_iatacode',\n",
    "       'aircraft_aircrafttype_icaocode', 'aircraft_aircrafttype_modelname',\n",
    "       'airlines_airline_name', \n",
    "       'airlines_operator_icaocode', 'airlines_operator_name',\n",
    "       'airports_destination_iatacode', 'airports_destination_icaocode',\n",
    "       'airports_destination_name', 'airports_next_iatacode',\n",
    "       'airports_next_icaocode', 'airports_next_name', 'countrytype_code',\n",
    "       'countrytype_description', 'flightnumbers_callsign',\n",
    "       'flightnumbers_iataflightnumber', 'flightnumbers_icaoflightnumber',\n",
    "       'flightnumbers_internalflightnumber',\n",
    "       'flightnumbers_operatoriataflightnumber',\n",
    "       'flightnumbers_operatoricaoflightnumber',\n",
    "       'flightnumbers_operatorinternalflightnumber', 'flightnumbers_operatortripnumber','flightnumbers_tripnumber', 'flightstatus_code',\n",
    "       'flightstatus_description', 'gid', 'last_update_fme', 'servicetype_description',\n",
    "       'servicetype_iatacode', 'timestamps_aobt', 'timestamps_eobt',\n",
    "       'timestamps_modificationdate', 'timestamps_sobt','day','month','year','hour','minute','delay','Pression au niveau mer',\n",
    "       'Variation de pression en 3 heures', 'Type de tendance barométrique',\n",
    "       'Direction du vent moyen 10 mn', 'Vitesse du vent moyen 10 mn',\n",
    "       'Température', 'Point de rosée', 'Humidité', 'Visibilité horizontale',\n",
    "       'Pression station', 'Rafales sur une période',\n",
    "       'Periode de mesure de la rafale']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbis['quarter'] = dbis.timestamps_sobt.dt.quarter\n",
    "dbis['day_of_week'] = dbis.timestamps_sobt.dt.dayofweek\n",
    "dbis['day_of_year'] = dbis.timestamps_sobt.dt.dayofyear\n",
    "dbis['day_of_week_name'] = dbis.timestamps_sobt.dt.weekday_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbis.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "lb_make = LabelEncoder()\n",
    "\n",
    "dbis[[ 'aircraft_aircrafttype_iatacode',\n",
    "       'aircraft_aircrafttype_icaocode', 'aircraft_aircrafttype_modelname',\n",
    "       'airlines_airline_name', \n",
    "       'airlines_operator_icaocode', 'airlines_operator_name',\n",
    "       'airports_destination_iatacode', 'airports_destination_icaocode',\n",
    "       'airports_destination_name', 'airports_next_iatacode',\n",
    "       'airports_next_icaocode', 'airports_next_name', 'countrytype_code',\n",
    "       'countrytype_description', 'flightnumbers_callsign',\n",
    "       'flightnumbers_iataflightnumber', 'flightnumbers_icaoflightnumber',\n",
    "       'flightnumbers_internalflightnumber',\n",
    "       'flightnumbers_operatoriataflightnumber',\n",
    "       'flightnumbers_operatoricaoflightnumber',\n",
    "       'flightnumbers_operatorinternalflightnumber', 'flightnumbers_operatortripnumber','flightnumbers_tripnumber', 'flightstatus_code',\n",
    "       'flightstatus_description', 'gid', 'last_update_fme', 'servicetype_description',\n",
    "       'servicetype_iatacode', 'timestamps_aobt', 'timestamps_eobt',\n",
    "       'timestamps_modificationdate', 'timestamps_sobt','day_of_week_name']]=dbis[[ 'aircraft_aircrafttype_iatacode',\n",
    "       'aircraft_aircrafttype_icaocode', 'aircraft_aircrafttype_modelname',\n",
    "       'airlines_airline_name', \n",
    "       'airlines_operator_icaocode', 'airlines_operator_name',\n",
    "       'airports_destination_iatacode', 'airports_destination_icaocode',\n",
    "       'airports_destination_name', 'airports_next_iatacode',\n",
    "       'airports_next_icaocode', 'airports_next_name', 'countrytype_code',\n",
    "       'countrytype_description', 'flightnumbers_callsign',\n",
    "       'flightnumbers_iataflightnumber', 'flightnumbers_icaoflightnumber',\n",
    "       'flightnumbers_internalflightnumber',\n",
    "       'flightnumbers_operatoriataflightnumber',\n",
    "       'flightnumbers_operatoricaoflightnumber',\n",
    "       'flightnumbers_operatorinternalflightnumber', 'flightnumbers_operatortripnumber','flightnumbers_tripnumber', 'flightstatus_code',\n",
    "       'flightstatus_description', 'gid', 'last_update_fme', 'servicetype_description',\n",
    "       'servicetype_iatacode', 'timestamps_aobt', 'timestamps_eobt',\n",
    "       'timestamps_modificationdate', 'timestamps_sobt','day_of_week_name']].apply(lb_make.fit_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,  dbis['delay'], test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dmatrix = xgb.DMatrix(data=X,label=dbis['delay'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_reg = xgb.XGBRegressor(objective ='reg:linear', colsample_bytree = 0.3, learning_rate = 0.1,\n",
    "                max_depth = 5, alpha = 10, n_estimators = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_reg.fit(X_train,y_train)\n",
    "\n",
    "preds = xg_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = np.sqrt(mean_squared_error(y_test, preds))\n",
    "print(\"RMSE: %f\" % (rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\"objective\":\"reg:linear\",'colsample_bytree': 0.3,'learning_rate': 0.1,\n",
    "                'max_depth': 5, 'alpha': 10}\n",
    "\n",
    "cv_results = xgb.cv(dtrain=data_dmatrix, params=params, nfold=3,\n",
    "                    num_boost_round=50,early_stopping_rounds=10,metrics=\"rmse\", as_pandas=True, seed=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print((cv_results[\"test-rmse-mean\"]).tail(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_reg = xgb.train(params=params, dtrain=data_dmatrix, num_boost_round=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "xgb.plot_importance(xg_reg)\n",
    "plt.rcParams['figure.figsize'] = [20, 30]\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=dbis.drop(['delay','timestamps_aobt','timestamps_eobt','last_update_fme',\n",
    "       'timestamps_modificationdate','gid','flightstatus_code'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = X.columns\n",
    "target = dbis['delay'].name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from scipy.stats import pearsonr\n",
    "correlations = {}\n",
    "for f in features:\n",
    "    data_temp = dbis[[f,target]]\n",
    "    x1 = data_temp[f].values\n",
    "    x2 = data_temp[target].values\n",
    "    key = f + ' vs ' + target\n",
    "    correlations[key] = pearsonr(x1,x2)[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_correlations = pd.DataFrame(correlations, index=['Value']).T\n",
    "data_correlations.loc[data_correlations['Value'].abs().sort_values(ascending=False).index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = plt.figure(figsize=(19, 15))\n",
    "plt.matshow(dbis.corr(), fignum=f.number)\n",
    "plt.xticks(range(dbis.shape[1]), dbis.columns, fontsize=14, rotation=45)\n",
    "plt.yticks(range(dbis.shape[1]), dbis.columns, fontsize=14)\n",
    "cb = plt.colorbar()\n",
    "cb.ax.tick_params(labelsize=14)\n",
    "plt.title('Correlation Matrix', fontsize=16);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import io\n",
    "import requests\n",
    "url=\"https://public.opendatasoft.com/explore/dataset/donnees-synop-essentielles-omm/download/?format=csv&q=Lyon&refine.nom_epci=CC+de+l%27Est+Lyonnais+(CCEL)&timezone=Europe/Berlin&lang=fr&use_labels_for_header=true&csv_separator=%3B\"\n",
    "s=requests.get(url).content\n",
    "c=pd.read_csv(io.StringIO(s.decode('utf-8')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://public.opendatasoft.com/api/records/1.0/search/?dataset=donnees-synop-essentielles-omm&q=Lyon&sort=date&facet=date&facet=nom&facet=temps_present&facet=libgeo&facet=nom_epci&facet=nom_dept&facet=nom_reg&refine.nom_epci=CC+de+l%27Est+Lyonnais+(CCEL)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "import time\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "response = requests.get(url)\n",
    "data_json=response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meteo = pd.read_csv(\"donnees-synop-essentielles-omm.csv\",sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meteo.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_json['records'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.io.json import json_normalize\n",
    "meteo=json_normalize(data_json['records'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meteo1=meteo[['Date', 'Pression au niveau mer',\n",
    "       'Variation de pression en 3 heures', 'Type de tendance barométrique',\n",
    "       'Direction du vent moyen 10 mn', 'Vitesse du vent moyen 10 mn',\n",
    "       'Température', 'Point de rosée', 'Humidité', 'Visibilité horizontale', 'Pression station','Rafales sur une période',\n",
    "       'Periode de mesure de la rafale',\n",
    "       'Précipitations dans la dernière heure']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meteo1.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shifted=meteo1.sort_values(by='Date').tail(50).shift(0)\n",
    "\n",
    "window = shifted.rolling(window=)\n",
    "\n",
    "means = window.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meteo1.sort_values(by='Date').tail(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(meteo1[\"Nebulosité totale\"].values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meteobis=spark.createDataFrame(meteo1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F\n",
    "meteobis=meteobis.withColumn(\"timestamp_30_before\", meteobis['Date'] - F.expr('INTERVAL 30 MINUTES') )\n",
    "meteobis=meteobis.withColumn(\"timestamp_30_after\", meteobis.Date + F.expr('INTERVAL 30 MINUTES') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meteobis.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list1=[]\n",
    "for item in data_json['records']:\n",
    "    list1.append(item['fields'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df = df.join(meteobis, [df.timestamps_sobt < meteobis.timestamp_30_after,meteobis.timestamp_30_before < df.timestamps_sobt], how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df.dropDuplicates(['aircraft_aircrafttype_iatacode','timestamps_eobt','airports_next_name']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df[\"timestamps_aobt\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=joined_df.dropDuplicates(['aircraft_aircrafttype_iatacode','timestamps_eobt','airports_next_name']).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1[['Pression au niveau mer',\n",
    "       'Variation de pression en 3 heures', 'Type de tendance barométrique',\n",
    "       'Direction du vent moyen 10 mn', 'Vitesse du vent moyen 10 mn',\n",
    "       'Température', 'Point de rosée', 'Humidité', 'Visibilité horizontale',\n",
    "       'Pression station', 'Rafales sur une période',\n",
    "       'Periode de mesure de la rafale',\n",
    "       'Précipitations dans la dernière heure']].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1[['Pression au niveau mer',\n",
    "       'Variation de pression en 3 heures', 'Type de tendance barométrique',\n",
    "       'Direction du vent moyen 10 mn', 'Vitesse du vent moyen 10 mn',\n",
    "       'Température', 'Point de rosée', 'Humidité', 'Visibilité horizontale',\n",
    "       'Pression station', 'Rafales sur une période',\n",
    "       'Periode de mesure de la rafale',\n",
    "       'Précipitations dans la dernière heure']].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.columns] = df[df.columns].apply(pd.to_numeric, errors='coerce')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
